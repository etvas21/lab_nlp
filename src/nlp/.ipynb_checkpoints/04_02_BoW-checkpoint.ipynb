{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2 Bag of Words(BoW)\n",
    "이번 챕터에서는 단어의 등장 순서를 고려하지 않는 빈도수 기반의 단어 표현 방법인 Bag of Words에 대해서 학습합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Bag of Words란?\n",
    "Bag of Words란 단어들의 순서는 전혀 고려하지 않고, 단어들의 출현 빈도(frequency)에만 집중하는 텍스트 데이터의 수치화 표현 방법입니다. \n",
    "\n",
    "Bag of Words를 직역하면 단어들의 가방이라는 의미입니다. 단어들이 들어있는 가방을 상상해봅시다. 갖고있는 어떤 텍스트 문서에 있는 단어들을 가방에다가 전부 넣습니다. 그러고나서 이 가방을 흔들어 단어들을 섞습니다. 만약, 해당 문서 내에서 특정 단어가 N번 등장했다면, 이 가방에는 그 특정 단어가 N개 있게됩니다. 또한 가방을 흔들어서 단어를 섞었기 때문에 더 이상 단어의 순서는 중요하지 않습니다.\n",
    "\n",
    "BoW를 만드는 과정을 이렇게 두 가지 과정으로 생각해보겠습니다.\n",
    "1. 우선, 각 단어에 고유한 정수 인덱스를 부여합니다.\n",
    "2. 각 인덱스의 위치에 단어 토큰의 등장 횟수를 기록한 벡터를 만듭니다.\n",
    "\n",
    "한국어 예제를 통해서 BoW에 대해서 이해해보도록 하겠습니다.\n",
    "\n",
    "**문서1 : 정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.**\n",
    "\n",
    "위의 문서1에 대해서 BoW를 만들어보도록 하겠습니다. 아래의 코드는 입력된 문서에 대해서 단어 집합(vocaburary)을 만들어 인덱스를 할당하고, BoW를 만드는 코드입니다. 이 코드에 이번에 입력할 입력은 문서1입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "import re\n",
    "okt = Okt()\n",
    "\n",
    "corpus = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['정부', '가', '발표', '하는', '물가상승률', '과', '소비자', '가', '느끼는', '물가상승률', '은', '다르다']\n"
     ]
    }
   ],
   "source": [
    "# cleansing\n",
    "sentense = re.sub(\"(\\.)\", \"\",corpus)\n",
    "\n",
    "# Word tokenize\n",
    "vocab = okt.morphs(sentense)\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9} \n",
      "\n",
      " [1, 2, 1, 1, 2, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "idx_vocab = {}\n",
    "bow =[]\n",
    "\n",
    "for word in vocab:\n",
    "    if word not in idx_vocab.keys():\n",
    "        idx_vocab[word] = len(idx_vocab)\n",
    "        bow.insert(len(idx_vocab)-1,1)\n",
    "    else:\n",
    "        idx = idx_vocab.get(word)\n",
    "        bow[idx] = bow[idx]+1\n",
    "        \n",
    "print(idx_vocab,'\\n\\n', bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
