{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7-3. 선형회기(Linear Regression)\n",
    "딥 러닝을 이해하기 위해서는 선형 회귀(Linear Regression)와 로지스틱 회귀(Logsitic Regression)를 이해할 필요가 있습니다. 이번 챕터에서는 머신 러닝에서 쓰이는 용어인 가설(Hypothesis), 손실 함수(Loss Function) 그리고 경사 하강법(Gradient Descent)에 대한 개념과 선형 회귀에 대해서 이해합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 선형 회귀(Linear Regression)\n",
    "시험 공부하는 시간을 늘리면 늘릴 수록 성적이 잘 나옵니다. 하루에 걷는 횟수를 늘릴 수록, 몸무게는 줄어듭니다. 집의 평수가 클수록, 집의 매매 가격은 비싼 경향이 있습니다. 이는 수학적으로 생각해보면 어떤 요인의 수치에 따라서 특정 요인의 수치가 영향을 받고있다고 말할 수 있습니다. 조금 더 수학적인 표현을 써보면 어떤 변수의 값에 따라서 특정 변수의 값이 영향을 받고 있다고 볼 수 있습니다. 다른 변수의 값을 변하게하는 변수를 x, 변수 x에 의해서 값이 종속적으로 변하는 변수 y라고 해봅시다.\n",
    "\n",
    "이때 변수 x의 값은 독립적으로 변할 수 있는 것에 반해, y값은 계속해서 x의 값에 의해서, 종속적으로 결정되므로 x를 독립 변수, y를 종속 변수라고도 합니다. 선형 회귀는 한 개 이상의 독립 변수 x와 y의 선형 관계를 모델링합니다. 만약, 독립 변수 x가 1개라면 단순 선형 회귀라고 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1) 단순 선형 회귀 분석(Simple Linear Regression Analysis)\n",
    "y=$W_{x}+b$  \n",
    "위의 수식은 단순 선형 회귀의 수식을 보여줍니다. 여기서 독립 변수 x와 곱해지는 값 W를 머신 러닝에서는 가중치(weight), 별도로 더해지는 값 b를 편향(bias)이라고 합니다. 직선의 방정식에서는 각각 직선의 기울기와 절편을 의미합니다. W와 b가 없이 y와 x란 수식은 y는 x와 같다는 하나의 식밖에 표현하지 못합니다. 그래프 상으로 말하면, 하나의 직선밖에 표현하지 못합니다.\n",
    "\n",
    "y=x  \n",
    "\n",
    "다시 말해 W와 b의 값을 적절히 찾아내면 x와 y의 관계를 적절히 모델링한 것이 됩니다.\n",
    "\n",
    "##### 2) 다중 선형 회귀 분석(Multiple Linear Regression Analysis)\n",
    "y=$ W_{1}x_{1}+ W_{2}x_{2} +...W_{n}x_{n}+b  $  \n",
    "잘 생각해보니까 집의 매매 가격은 단순히 집의 평수가 크다고 결정되는 게 아니라 집의 층의 수, 방의 개수, 지하철 역과의 거리와도 영향이 있는 것 같습니다. 이제 이러한 다수의 요소를 가지고 집의 매매 가격을 예측해보고 싶습니다. y는 여전히 1개이지만 이제 x는 1개가 아니라 여러 개가 되었습니다. 이제 이를 다중 선형 회귀 분석이라고 합니다. 이에 대한 실습은 뒤의 챕터에서 진행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 가설(Hypothesis) 세우기\n",
    "단순 선형 회귀를 가지고 문제를 풀어봅시다. 어떤 학생의 공부 시간에 따라서 다음과 같은 점수를 얻었다는 데이터가 있습니다.\n",
    "\n",
    "| hours(x) | scroe(y)\n",
    "| ---: | ---:\n",
    "|2|25\n",
    "|3|50\n",
    "|4|42\n",
    "|5|61\n",
    "\n",
    "알고있는 데이터로부터 x와 y의 관계를 유추하고, 이 학생이 6시간, 7시간, 8시간을 공부하였을 때의 성적을 예측해보고 싶습니다. x와 y의 관계를 유추하기 위해서 수학적으로 식을 세워보게 되는데 머신 러닝에서는 이러한 식을 **가설(Hypothesis)**이라고 합니다. 아래의 H(x)에서 H는 Hypothesis를 의미합니다. 사실 선형 회귀의 가설은 이미 아래와 같이 널리 알려져있습니다.\n",
    "\n",
    "H(x) = $W_{x} + b$\n",
    "\n",
    "**그래프**\n",
    "\n",
    "\n",
    "위의 그림은 W와 b의 값에 따라서 천차만별로 그려지는 직선의 모습을 보여줍니다. 중학교 수학 과정인 직선의 방정식을 알고있다면, 위의 가설에서 W는 직선의 기울기이고 b는 절편으로 직선을 표현함을 알 수 있습니다. 결국 선형 회귀는 주어진 데이터로부터 y와 x의 관계를 가장 잘 나타내는 직선을 그리는 일을 말합니다. 그리고 어떤 직선인지 결정하는 것은 W와 b의 값이므로 선형 회귀에서 해야할 일은 결국 적절한 W와 b를 찾아내는 일이 됩니다.\n",
    "\n",
    "아직은 방법을 모르지만, 어떤 방법을 사용하여 적절한 W와 b의 값을 찾은 덕택에 y와 x의 관계를 가장 잘 나타내는 직선을 위의 좌표 평면 상에서 그렸다고 한 번 가정해보겠습니다. 이 직선을 x가 6일때, 7일때, 8일때에 대해서도 계속해서 직선을 그저 이어그린다면 이 학생이 6시간을 공부했을 때, 7시간을 공부했을 때, 8시간을 공부했을 때의 예상 점수를 말할 수 있게 됩니다. 왜냐면 x가 각각 6일 때, 7일 때, 8일 때의 y값을 확인하면 되기 때문입니다.\n",
    "\n",
    "..................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 비용 함수(Cost function) : 평균 제곱 오차(MSE)\n",
    "앞서 주어진 데이터에서 x와 y의 관계를 W와 b를 이용하여 식을 세우는 일을 가설이라고 언급했습니다. 그리고 이제 해야할 일은 문제에 대한 규칙을 가장 잘 표현하는 W와 b를 찾는 일입니다. 머신 러닝은 W와 b를 찾기 위해서 실제값과 가설로부터 얻은 예측값의 오차를 계산하는 식을 세우고, 이 식의 값을 최소화하는 최적의 W와 b를 찾아냅니다.\n",
    "\n",
    "이 때 실제값과 예측값에 대한 오차에 대한 식을 **목적 함수(Objective function) 또는 비용 함수(Cost function) 또는 손실 함수(Loss function)**라고 합니다. 함수의 값을 최소화하거나, 최대화하거나 하는 목적을 가진 함수를 목적 함수(Objective function)라고 합니다. 그리고 값을 최소화하려고 하면 이를 비용 함수(Cost function) 또는 손실 함수(Loss function)라고 합니다. 이 책에서는 목적 함수, 비용 함수, 손실 함수란 용어를 같은 의미로 혼용해서 사용합니다.\n",
    "\n",
    "비용 함수는 단순히 실제값과 예측값에 대한 오차를 표현하면 되는 것이 아니라, 예측값의 오차를 줄이는 일에 최적화 된 식이어야 합니다. 앞으로 배울 러닝, 딥 러닝에는 다양한 문제들이 있고, 각 문제들에는 적합한 비용 함수들이 있습니다. **회귀 문제의 경우에는 주로 평균 제곱 오차(Mean Squered Error, MSE)**가 사용됩니다  \n",
    ".....  \n",
    "**그래프**  \n",
    ".....  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 옵티마이저(Optimizer) : 경사하강법(Gradient Descent)\n",
    "선형 회귀를 포함한 수많은 머신 러닝, 딥 러닝의 학습은 **결국 비용 함수를 최소화하는 매개 변수인 W와 b을 찾기 위한 작업을 수행합니다. 이때 사용되는 알고리즘을 옵티마이저(Optimizer) 또는 최적화 알고리즘**이라고 부릅니다.\n",
    "\n",
    "\n",
    "그리고 이 옵티마이저를 통해 **적절한 W와 b를 찾아내는 과정을 머신 러닝에서 학습(training)**이라고 부릅니다. 여기서는 가장 기본적인 옵티마이저 알고리즘인 **경사 하강법(Gradient Descent)**에 대해서 배웁니다.\n",
    "\n",
    "경사 하강법을 이해하기 위해서 cost와 기울기 W와의 관계를 이해해보겠습니다. W는 머신 러닝 용어로는 가중치라고 불리지만, 직선의 방정식 관점에서 보면 직선의 기울기를 의미하고 있습니다. 아래의 그래프는 기울기 W가 지나치게 높거나, 낮을 때 어떻게 오차가 커지는 보여줍니다.\n",
    ",..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. 케라스로 구현하는 선형 회귀\n",
    "케라스에 대해서는 뒤의 딥 러닝 챕터에서 더 자세히 배우겠지만, 우선 간단하게 케라스를 이용해서 선형 회귀를 구현해보도록 하겠습니다. 우선 케라스로 모델을 만드는 기본적인 형식은 다음과 같습니다. 아래의 코드는 아직 완전한 코드가 아니므로 실행이 불가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel = keras.models.Sequential()\\nmodel.add(keras.layers.Dense(1,input_dim=1))\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Dense(1,input_dim=1))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sequential로 model이라는 이름의 모델을 만들고, 그리고 add를 통해 필요한 사항들을 추가해갑니다. 첫번째 인자인 1은 출력의 차원을 의미하며, 두번째 인자인 input_dim은 입력의 차원을 정의하는데 이번 실습과 같이 1개의 실수 x를 가지고 하는 1개의 실수 y를 예측하는 단순 선형 회귀를 구현하는 경우에는 각각 1의 값을 가집니다. 이제 직접 실습을 진행해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers\n",
    "import numpy as np\n",
    "\n",
    "x=np.array([1,2,3,4,5,6,7,8,9]) # 공부하는 시간\n",
    "y=np.array([11,22,33,44,53,66,77,87,95]) # 각 공부하는 시간에 맵핑되는 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 10ms/sample - loss: 283.7624 - mse: 283.7624\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1097 - mse: 2.1097\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1109 - mse: 2.1109\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1120 - mse: 2.1120\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1131 - mse: 2.1131\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1141 - mse: 2.1141\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1152 - mse: 2.1152\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1161 - mse: 2.1161\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1171 - mse: 2.1171\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1180 - mse: 2.1180\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1189 - mse: 2.1189\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1198 - mse: 2.1198\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1206 - mse: 2.1206\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1214 - mse: 2.1214\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1222 - mse: 2.1222\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1230 - mse: 2.1230\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1237 - mse: 2.1237\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 5ms/sample - loss: 2.1244 - mse: 2.1244\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1251 - mse: 2.1251\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1258 - mse: 2.1258\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1265 - mse: 2.1265\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1271 - mse: 2.1271\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1277 - mse: 2.1277\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1283 - mse: 2.1283\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1289 - mse: 2.1289\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1294 - mse: 2.1294\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1300 - mse: 2.1300\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1305 - mse: 2.1305\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 5ms/sample - loss: 2.1310 - mse: 2.1310\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1315 - mse: 2.1315\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1319 - mse: 2.1319\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1324 - mse: 2.1324\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1328 - mse: 2.1328\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1333 - mse: 2.1333\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1337 - mse: 2.1337\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1341 - mse: 2.1341\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1345 - mse: 2.1345\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1349 - mse: 2.1349\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1352 - mse: 2.1352\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1356 - mse: 2.1356\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1359 - mse: 2.1359\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1362 - mse: 2.1362\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1366 - mse: 2.1366\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1369 - mse: 2.1369\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1372 - mse: 2.1372\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1375 - mse: 2.1375\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1377 - mse: 2.1377\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1380 - mse: 2.1380\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1383 - mse: 2.1383\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1385 - mse: 2.1385\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1388 - mse: 2.1388\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1390 - mse: 2.1390\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1392 - mse: 2.1392\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1395 - mse: 2.1395\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1397 - mse: 2.1397\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 5ms/sample - loss: 2.1399 - mse: 2.1399\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1401 - mse: 2.1401\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.4860 - mse: 2.486 - 0s 4ms/sample - loss: 2.1403 - mse: 2.1403\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1405 - mse: 2.1405\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1406 - mse: 2.1406\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1408 - mse: 2.1408\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1410 - mse: 2.1410\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1412 - mse: 2.1412\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1413 - mse: 2.1413\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1415 - mse: 2.1415\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1416 - mse: 2.1416\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1418 - mse: 2.1418\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1419 - mse: 2.1419\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1420 - mse: 2.1420\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1422 - mse: 2.1422\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1423 - mse: 2.1423\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1424 - mse: 2.1424\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1425 - mse: 2.1425\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1426 - mse: 2.1426\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1428 - mse: 2.1428\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1429 - mse: 2.1429\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1430 - mse: 2.1430\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1431 - mse: 2.1431\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1432 - mse: 2.1432\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1433 - mse: 2.1433\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1434 - mse: 2.1434\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1434 - mse: 2.1434\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1435 - mse: 2.1435\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1436 - mse: 2.1436\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1437 - mse: 2.1437\n",
      "Epoch 86/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1438 - mse: 2.1438\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1438 - mse: 2.1438\n",
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1439 - mse: 2.1439\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1440 - mse: 2.1440\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1440 - mse: 2.1440\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1441 - mse: 2.1441\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1442 - mse: 2.1442\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1442 - mse: 2.1442\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1443 - mse: 2.1443\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1443 - mse: 2.1443\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1444 - mse: 2.1444\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1445 - mse: 2.1445\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1445 - mse: 2.1445\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1446 - mse: 2.1446\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1446 - mse: 2.1446\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1447 - mse: 2.1447\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1447 - mse: 2.1447\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1447 - mse: 2.1447\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1448 - mse: 2.1448\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1448 - mse: 2.1448\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1449 - mse: 2.1449\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1449 - mse: 2.1449\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1449 - mse: 2.1449\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1450 - mse: 2.1450\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1450 - mse: 2.1450\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1450 - mse: 2.1450\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1451 - mse: 2.1451\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1451 - mse: 2.1451\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1451 - mse: 2.1451\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1452 - mse: 2.1452\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1452 - mse: 2.1452\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1452 - mse: 2.1452\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1453 - mse: 2.1453\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1453 - mse: 2.1453\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1453 - mse: 2.1453\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1453 - mse: 2.1453\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1453 - mse: 2.1453\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1454 - mse: 2.1454\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1454 - mse: 2.1454\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1454 - mse: 2.1454\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1454 - mse: 2.1454\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1454 - mse: 2.1454\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1455 - mse: 2.1455\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1455 - mse: 2.1455\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1455 - mse: 2.1455\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1455 - mse: 2.1455\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1455 - mse: 2.1455\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 5ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1456 - mse: 2.1456\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1457 - mse: 2.1457\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1458 - mse: 2.1458\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 171/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 7ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 174/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 8ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 5ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1459 - mse: 2.1459\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 8ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 6ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 5ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 4ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 256/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 260/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 3ms/sample - loss: 2.1460 - mse: 2.1460\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 2ms/sample - loss: 2.1460 - mse: 2.1460\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f642c043630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Model \n",
    "model = Sequential()\n",
    "\n",
    "# Ouput Demension : 1 , Input Demension: 1 \n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "\n",
    "# Learning Rate = 0.01\n",
    "# sgd: Gradient Descent\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "\n",
    "# Loss Function: mse(Mean Sequared Error)\n",
    "model.compile(optimizer=sgd, loss='mse',metrics=['mse'])\n",
    "\n",
    "model.fit(x,y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 코드는 간단하지만, 지금까지 배운 것들이 집대성 된 코드입니다. \n",
    "\n",
    "- 우선 공부한 시간을 x, \n",
    "- 각 공부한 시간에 따른 성적을 y라고 해봅시다. \n",
    "- activation은 어떤 함수를 사용할 것인지를 의미하는데 선형 회귀를 사용할 경우에는 linear라고 기재합니다.\n",
    "- 옵티마이저로는 경사 하강법의 일종인 확률적 경사 하강법을 사용하였으며, \n",
    "- 학습률은 0.01로 정하였습니다. \n",
    "- 손실 함수로는 평균 제곱 오차를 사용합니다. \n",
    "- 그리고 전체 데이터에 대한 훈련 횟수는 300으로 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "전체 데이터에 대한 훈련 횟수는 300으로 하였지만, 어느 순간 오차가 더 이상 줄어들지 않는데 이는 오차를 최소화하는 가중치 W와 b를 찾았기 때문으로 추정이 가능합니다. 이제 최종적으로 선택된 오차를 최소화하는 직선을 그래프로 그려보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f642c0d0668>,\n",
       " <matplotlib.lines.Line2D at 0x7f642c0d0860>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAd1ElEQVR4nO3deZSU5ZXH8e+1sca4JKigYzQJJiY2alywo5YoKWhxFDWajKJRM8Y4otEYozEqalxDECOoSdwQVBSiGNABFdlKCkFLlE1BQERchk2acWexoPvOH0+RIGHphqp+6636fc7x0N30co9Hf1zured9zN0REZH42SbqAkREZMsowEVEYkoBLiISUwpwEZGYUoCLiMRUi+b8Ya1atfI2bdo0548UEYm9KVOmLHP31ut/vFkDvE2bNkyePLk5f6SISOyZ2Xsb+rhGKCIiMaUAFxGJKQW4iEhMKcBFRGJKAS4iElMKcBGRmFKAi4gUUTabpWfPnmSz2YJ/72Z9HbiISCXJZrPU1taSy+VIJBKk02mSyWTBvr86cBGRIslkMuRyOerr68nlcmQymYJ+fwW4iEiRpFIpEokEVVVVJBIJUqlUQb+/RigiIkWSTCZJp9OMGJGhS5dUQccnoA5cRKRoli+HoUOT9OnTnV12KWx4gzpwEZGieOYZuPhieP996NYNdtut8D9DHbiISAEtWgSnnQYnnQQ77ggTJ8L998POOxf+ZynARUQKoL4e7r4bqqtD992jB0ybBu3bF+9naoQiIrKVXnstjEleeQU6d4Z77oF99in+z1UHLiKyhZYvh9/9Dg49FN59FwYNglGjmie8QR24iMgWGTECLroI3nsPzj8fbr0VdtmleWtQBy4i0gSLFkHXrnDCCbDDDjBhAvTt2/zhDQpwEZFGqa8Ps+22bWH4cPjDH8KS8qijoqtJIxQRkc147TW44AKYNAmOOQbuvbf55tybog5cRGQjli+HK68MS8r582HgQBg9ujTCG9SBi4hs0HPPhSXlu+/Cf/839OoVzZx7U9SBi4isY/FiOP106NIFttsOxo+HBx4ovfAGBbiICAANDWG2XV0Nw4bBLbfA9OnQoUPUlW2cRigiUhay2SyZTIZUqumPbX399bCkfPllqK0NQf7d7xap0AJSgItI7G3p1WUrVsDNN0Pv3tCyJTz6KJx1Fpg1Q9EFoBGKiMTellxdNnIk7L9/WE7+13/BnDlw9tnxCW9QgItIGWjK1WWLF8MZZ8Dxx4clZSYD/fvDrrs2W7kFoxGKiMTe2qvLNjUDb2gIR96vvhpWrQqjkyuvhH/7twgKLhAFuIiUhWQyudG594wZYUmZzUKnTmFJ+b3vNXOBRaARioiUrRUroHt3aNcO5s6FAQNg7NjyCG9QBy4iZWrkyHCS8p134Nxz4bbboFWrqKsqLHXgIlJWliyBn/40LCkTCRg3Dh58sPzCGxTgIlImGhrC5cHV1fDkk3DTTeEpgpt4QUrsaYQiIrE3c2ZYUr70EnTsGJaU++4bdVXFpw5cRGJrxQq45ho45BB480146CFIpysjvEEduIjE1KhRYUk5fz78/Ofwpz+V55x7U9SBi0isfPABnHkmHHcctGgRlpQPPVR54Q0KcBGJiYaG8Fzu6moYOhRuvDE8RbCcl5Sb06gAN7PLzOwNM5tpZo+Z2XZmtreZTTKzeWY22MwSxS5WRCrTG2+E53J36wYHHRReXXLDDfE+Bl8Imw1wM9sT+DVQ4+4HAFXAGUAv4A533wf4CDivmIWKSOVZuRKuvRYOPhhmzw6jknHjQhcujR+htAC+YmYtgO2BxUAnYEj+9wcApxS+PBGpVGPGwAEHwB//GJ7RPWdOWFbG6XGvxbbZAHf3hcDtwPuE4P4EmAJ87O5r8p+2ANizWEWKSOVYujQE9rHHQlUVPP88PPwwtG4ddWWlpzEjlJ2Bk4G9ga8DOwDHNfYHmFk3M5tsZpPr6uq2uFARKW8NDdCvXxiP/P3vcP31YUnZsWPUlZWuxoxQjgHecfc6d18NPAm0B1rmRyoAewELN/TF7t7X3Wvcvaa1/ggVkQ2YNQt++EM4/3z4/vdDcN90U7hwQTauMQH+PnCEmW1vZgbUArOAccCp+c85BxhWnBJFpFytXAnXXReWlLNmhYdOZTJaUjZWY2bgkwjLyqnAjPzX9AWuAi43s3nArkD/ItYpImVm7NjQbffoEa44mzMnPPZVS8rGa9RRene/AbhhvQ/PBw4reEUiUtaWLoXf/hYGDoR99glBXlsbdVXxpJOYItIk2WyWnj17ks1mm/R1DQ3h8uDqahg8GH7/+3DVmcJ7y+lhViLSaNlsltraWnK5HIlEgnQ6vdF7KNc1axZceCFMmABHHx2e2922bTMUXObUgYtIo2UyGXK5HPX19eRyOTKZzCY/f9Wq0GkffHB4Zne/fmFJqfAuDHXgItJoqVSKRCLxjw48tYknSaXToeueNw/OPht694bddmu+WiuBAlxEGi2ZTJJOp8lkMqRSqQ2OT+rqwpLy0UfDknLMGDjmmAiKrQAKcBFpkmQyucHgdg8Pm/rd7+Czz8Lru6+5Br7ylQiKrBAKcBHZarNnh3HJCy/AUUeFJeV++0VdVfnTElNEttiqVeGZJQcdFI6/P/AAjB+v8G4u6sBFZIs8/3zout96Kzw9sHdv2H33qKuqLOrARaRJ6urgnHPCAZyGBhg9OpyqVHg3PwW4iDTK2iVldTX87W/hppwZM6Bz56grq1waoYjIZs2ZE8Yl48dD+/ZhSbn//lFXJerARWSjVq0Kt7+vvUi4b9/wShOFd2lQBy4iGzRuXOi6586FM8+EPn005y416sBF5EuWLQuXB3fqBGvWwKhRMGiQwrsUKcBFBAhLyocfDkvKQYOge/fwAKpjj426MtkYjVBEhDffDOOSTAaOPDIsKQ84IOqqZHPUgYtUsC++CJcHH3ggTJsWgnvCBIV3XKgDF6lQmUzout98E37607Ck/Pd/j7oqaQp14CIVZtmycHlwx46Qy8HIkeFgjsI7fhTgIhXCHQYMCEvKgQPh6qvDkvI//iPqymRLaYQiUgHmzg3jknHjIJkMs+7vfz/qqmRrqQMXKWNffAE33xzCeupUuPdemDhR4V0u1IGLlKnx4+GCC8KS8vTT4Y47YI89oq5KCkkduEiZ+b//g1/8AlKp0IGPGAGPP67wLkcKcJESlc1m6dmzJ9lstlGf7x4uEq6uhkcegauugjfegOOPL3KhEhmNUERKUDabpba2llwuRyKRIJ1Ob/Ai4bXmzoVf/jLcknPEEWFJeeCBzViwREIduEgJymQy5HI56uvryeVyZDKZDX7eF1/ALbeEsJ4yJSwpX3xR4V0p1IGLlKBUKkUikfhHB55Kpf7lc154ISwp58yBrl3hzjs15640CnCREpRMJkmn02QyGVKp1JfGJx9+CFdeCf37w7e+Bc8+C126RFisREYBLlKiksnkl4LbPTzm9fLL/xni118PO+wQYZESKQW4SAy89VZYUqbTcPjhMGZMuOZMKpuWmCIlLJeDP/whnJx89VW4556wpFR4C6gDFylZEyaEJeXs2XDaaWFJ+fWvR12VlBJ14CIl5sMP4fzzoUMHWLECnnkGnnhC4S3/SgEuUiLWLimrq+Ghh+CKK8JJyhNOiLoyKVUaoYiUgHnzwpJy7Fg47DAYPRoOPjjqqqTUqQMXiVAuBz16hDsoJ02Cv/4VXnpJ4S2N06gAN7OWZjbEzOaY2WwzS5rZLmY2xszeyv+6c7GLFSknEyfCIYfAddfBSSeFE5UXXwxVVVFXJnHR2A78LmCku1cDBwGzgauBtLt/F0jn3xeRzfjoI+jWDY4+Gj7/HJ5+Gv7+dy0ppek2G+Bm9jWgA9AfwN1z7v4xcDIwIP9pA4BTilWkSDlwh8ceC0vKBx/855LyxBOjrkziqjFLzL2BOuAhMzsImAJcCuzu7ovzn7ME2L04JYrE39tvw0UXheXkD34Ao0Zpzi1brzEjlBZAO+Bedz8EWM564xJ3d8A39MVm1s3MJpvZ5Lq6uq2tVyRWcjno2TMsKbNZ+Mtfwq8KbymExgT4AmCBu0/Kvz+EEOgfmNkeAPlfl27oi929r7vXuHtN69atC1GzSCy8+CK0awfXXBNeyz17NvzqV1pSSuFsNsDdfQnwv2a2b/5DtcAsYDhwTv5j5wDDilKhSMx89FE4An/UUfDZZzB8OAwZAnvuGXVlUm4ae5DnEmCQmSWA+cC5hPB/wszOA94DuhanRJF4cIfBg+E3v4G6Ovjtb+HGG2HHHaOuTMpVowLc3acDNRv4rdrCliMST/PnhyXlqFFQUwPPPRde4y1STDqJKbIVVq+GW2+F/fcPM+8//xleflnhLc1Dz0IR2UIvvRRm3TNnwo9/HMJ7r72irkoqiTpwkSb6+OPw4Kn27eGTT2DYMHjySYW3ND8FuEgjrV1SVldD375w2WUwaxb86EdRVyaVSiMUkUZ4552wpBw5Eg49FEaMCK/xFomSOnCRTVi9Gnr1CkvKiRPhrrvCY18V3lIK1IGLbEQ2G5aUM2ZoSSmlSR24yHo+/jiMS9q3D6cq/+d/tKSU0qQAF8lzD5cHt20L998Pl14alpQnnxx1ZSIbphGKVLxsNstTT2WYODFFNpukXbtwE/yhh0ZdmcimKcClok2YkKW2tpbVq3NAgksvTXP77Ula6P8MiQGNUKRivfwydO2ayYd3PVVVOXbfPaPwlthQgEvF+eSTcHnwkUfCmjUpEokEVVVVJBIJUqlU1OWJNJp6DakY7jB0KPz61/DBB+HXW25JMnNmmkwmQyqVIplMRl2mSKMpwKUivPtuuA3n2WfDkwKHDw+PfQVIJpMKbokljVCkrK1eDbffHk5SZjLQpw+88so/w1skztSBS9maNCmcpHztNTjpJPjrX+Gb34y6KpHCUQcuZeeTT8K4JJmEZcvCKcphwxTeUn4U4FI21i4p99sP7rkHLrkknKT88Y/BLOrqRApPAS5l4b33wnO5Tz0VdtstjE/uugu++tWoKxMpHgW4xNqaNdC7d+i6n38+vP3qq/CDH0RdmUjxaYkpsfXKK2FJOX06nHhiWFJ+61tRVyXSfNSBS+x8+mk4hHPEEbB0aZh7Dx+u8JbKow5cYsMdnnoqLCcXLw7H4Xv00JxbKpc6cImF998Pz+X+z/+E1q3Dg6j+8heFt1Q2BbiUtDVrwunJ/faDdDqcqpw8GQ47LOrKRKKnEYqUrMmToVs3mDYNTjgB7r5bc26RdakDl5Lz6afhOrPDD4clS2DIEHj6aYW3yPrUgUvJcA8XCF9yCSxaFC4W7tEDvva1qCsTKU3qwKUkvP8+nHIK/OQnsOuukM2G13UrvEU2TgEuzSabzdKzZ0+y2ew/PrZmDdxxR1hSjhkDt90WZt+HHx5hoSIxoRGKNItsNlwenMvlSCQSpNNpEokk3brB1KnQpUtYUrZpE3WlIvGhDlyaRSaTIZfLUV9fTy6X44orMhx2WJh1P/EEPPOMwlukqRTg0ixSqXB58DbbVNHQkOCll1JceCHMmQOnnabHvYpsCY1QpFnstVeSmpo0EyZk+Pa3UwwalOSII6KuSiTeFOBSVPX14dUk110H9fVJbr01yeWXw7bbRl2ZSPwpwKVopkwJj3udMgWOOy7ckrP33lFXJVI+NAOXgvvsM7jssvC8koULYfBgGDFC4S1SaOrApaCGDQsXCi9cCBdeCH/8I7RsGXVVIuWp0R24mVWZ2TQzeyb//t5mNsnM5pnZYDNLFK9MKXULFoTLg085JQT2iy+GkYnCW6R4mjJCuRSYvc77vYA73H0f4CPgvEIWJvFQXw9//jO0bQujRsGtt4aDOclk1JWJlL9GBbiZ7QWcAPTLv29AJ2BI/lMGAKcUo0ApXVOnhiPvl14K7dvDzJlw1VV6hYlIc2lsB34ncCXQkH9/V+Bjd1+Tf38BsOeGvtDMupnZZDObXFdXt1XFSmn4/HO4/PJw8/uCBfD44/Dcc/Dtb0ddmUhl2WyAm9mJwFJ3n7IlP8Dd+7p7jbvXtG7deku+hZSQ4cPDg6fuuAPOPz+cpDz9dJ2kFIlCY16F0h74kZl1AbYDvgrcBbQ0sxb5LnwvYGHxypSoLVwYboJ/8knYf/+wpDzyyKirEqlsm+3A3b27u+/l7m2AM4Dn3f0sYBxwav7TzgGGFa1KiUx9fbg8uG3b8Frunj3D7FvhLRK9rTnIcxVwuZnNI8zE+xemJCkV06bBEUeEzjuZhDfegKuvhoReMCpSEpp0kMfdM0Am//Z8QHeDl6HPP4cbboA774RWreCxxzTnFilFOokpX/LMM3DxxeGKs27dwuu6d9456qpEZEP0LBQBwpLy1FPhpJNgp51g4kS4/36Ft0gpU4BXuLWPe23bFp59Njy7ZOrUcDBHREqbRigVbPr0MCZ59VXo3BnuvRe+852oqxKRxlIHXoGWL4crroCaGnjvPRg0KDzHROEtEi/qwCvMukvK888PS8pddom6KhHZEurAK8SiReHy4JNOgh13hAkToG9fhbdInCnAy1x9Pdx9N1RXw9NPQ48e4YDOUUdFXZmIbC2NUMpQNpslk8mw554p7r47ySuvwDHHhCXlPvtEXZ2IFIoCvMxks1lqa2tZtSqHe4KWLdMMHJjkzDN1klKk3GiEUmbuvz/DypU53Osxy/GrX2U46yyFt0g5UoCXiUWLoGtXGDAghVmCbbapYrvtEnTpkoq6NBEpEo1QYq6+Phx5794dvvgCbrklSYcOaV58MUMqlSKpyylFypYCPMZefz2cpJw0CWprw5Lyu98FSNKhg4JbpNxphBJDy5eHy4PbtYO334ZHH4UxY9aGt4hUCnXgMfPcc3DRRfDuu3DeedCrF+y6a9RViUgU1IHHxOLF4VKFLl1gu+1g/Hjo10/hLVLJFOAlrqEhzLarq2HYMLj55vAUwQ4doq5MRKKmEUoJmzEjLClffhk6dQpB/r3vRV2ViJQKdeAlaMWKcHlwu3Ywbx488giMHavwFpEvUwdeYkaODEvKd96BX/wCbrtNc24R2TB14CViyRI44ww4/nhIJCCTgf79Fd4isnEK8Ig1NISTlNXV8NRTcNNN8Npr8MMfRl2ZiJQ6jVAiNHNmWFJms9CxI9x3n+bcItJ46sAjsGJFeHbJIYfA3LkwYACk0wpvEWkadeDNbNSosKScPx9+/nP405+gVauoqxKROFIH3kyWLIEzz4TjjoNtt4Vx4+ChhxTeIrLlFOBF1tAQLg9u2xaGDoUbbwxLylQq6spEJO40QimimTPhggvgpZdCYN93H+y7b9RViUi5UAdeBCtXwrXXhiXlm2/Cww/D888rvEWksNSBF9iYMXDhhVpSikjxqQMvkA8+gLPOgmOPhRYtQsetJaWIFJMCfCs1NMADD4STlEOGwA03hCVlx45RVyYi5U4jlK0wa1ZYUk6cGI6+33dfCHIRkeagDnwLrFwJ110HBx6YZcqUnlx7bZZx4xTeItK81IE30dixYUn59ttZqqpqyeVy9OmT4IQT0iSTugleRJqPOvBGWroUzj4bOneGbbaB887LADnq6+vJ5XJkMpmIKxSRSqMA34yGhnB5cHU1PPEEXH89vP46nHdeikQiQVVVFYlEgpSOVopIM9vsCMXMvgE8AuwOONDX3e8ys12AwUAb4F2gq7t/VLxSm9+sWWFcMmFCuET4vvvCkXiAZDJJOp0mk8mQSqU0PhGRZmfuvulPMNsD2MPdp5rZTsAU4BTg58CH7n6rmV0N7OzuV23qe9XU1PjkyZMLU3kRrVoFPXpAr16w005w++3hUI5Z1JWJSCUysynuXrP+xzfbgbv7YmBx/u3PzGw2sCdwMpDKf9oAIANsMsDjYOxY+OUvw2XCP/sZ9O4NrVtHXZWIyL9q0gzczNoAhwCTgN3z4Q6whDBi2dDXdDOzyWY2ua6ubitKLa66uhDYnTuH98eODbfBK7xFpFQ1OsDNbEdgKPAbd/903d/zMIfZ4CzG3fu6e42717QuwTR0hwcfDEvKwYPh97+HGTOgtjbqykRENq1RrwM3s20J4T3I3Z/Mf/gDM9vD3Rfn5+RLi1VkscyeHZaUL7wARx8dLhdeu6QUESl1m+3AzcyA/sBsd++zzm8NB87Jv30OMKzw5RXHqlXh5YAHHRS67X79IJNReItIvDSmA28P/AyYYWbT8x+7BrgVeMLMzgPeA7oWp8TCSqfDkvKtt8LBnN69Ybfdoq5KRKTpGvMqlInAxl5AF5tJcV0dXHFFWEx+5zvhud3HHBN1VSIiW67sT2K6h+dyV1fDY4+Fh1DNmKHwFpH4K+uHWc2ZE5aU48fDUUeFJeV++0VdlYhIYZRlB75qVbhY4aCDwuUKDzwQQlzhLSLlpOw68HHjQtc9d2644qx3b9h9g0eMRETirWw68GXLwvNKOnWC+noYPRoGDlR4i0j5in2Au8PDD4cl5aBBcO21YUm59ki8iEi5ivUI5c03w7gkk4H27cOScv/9o65KRKR5xLID/+ILuPFGOPBAmD4d+vYNx+EV3iJSSWLXgWcy4Sb4uXPhzDOhTx/NuUWkMsWmA1+2DM49Fzp2hDVrYNSoMPNWeItIpYpFgD/ySFhSDhwI3bvDzJlw7LFRVyUiEq1YjFBGjYJ99w1LygMOiLoaEZHSEIsAv/9+2H572CYWf18QEWkesYjEGTOy9OrVk2w2G3UpIiIlo+Q78Gw2S21tLblcjkQiQTqdJplMRl2WiEjkSr4Dz2Qy5HI56uvryeVyZDKZqEsSESkJJR/gqVSKRCJBVVUViUSCVCoVdUkiIiWh5EcoyWSSdDpNJpMhlUppfCIiklfyAQ4hxBXcIiJfVvIjFBER2TAFuIhITCnARURiSgEuIhJTCnARkZhSgIuIxJS5e/P9MLM64L0t/PJWwLICllMoqqtpVFfTqK6mKde6vuXurdf/YLMG+NYws8nuXhN1HetTXU2juppGdTVNpdWlEYqISEwpwEVEYipOAd436gI2QnU1jepqGtXVNBVVV2xm4CIi8mVx6sBFRGQdCnARkZgq+QA3swfNbKmZzYy6lnWZ2TfMbJyZzTKzN8zs0qhrAjCz7czsFTN7LV/XTVHXtJaZVZnZNDN7Jupa1mVm75rZDDObbmaTo65nLTNraWZDzGyOmc02s8ifqWxm++b/Pa3951Mz+03UdQGY2WX5/+ZnmtljZrZd1DUBmNml+ZreKPS/q5KfgZtZB+Bz4BF3PyDqetYysz2APdx9qpntBEwBTnH3WRHXZcAO7v65mW0LTAQudfeXo6wLwMwuB2qAr7r7iVHXs5aZvQvUuHtJHQAxswHABHfvZ2YJYHt3/zjqutYysypgIXC4u2/pAb1C1bIn4b/1/dx9pZk9AYxw94cjrusA4HHgMCAHjAQudPd5hfj+Jd+Bu/sLwIdR17E+d1/s7lPzb38GzAb2jLYq8ODz/Lvb5v+J/E9pM9sLOAHoF3UtcWBmXwM6AP0B3D1XSuGdVwu8HXV4r6MF8BUzawFsDyyKuB6AtsAkd1/h7muA8cBPCvXNSz7A48DM2gCHAJOirSTIjyqmA0uBMe5eCnXdCVwJNERdyAY4MNrMpphZt6iLydsbqAMeyo+d+pnZDlEXtZ4zgMeiLgLA3RcCtwPvA4uBT9x9dLRVATATONrMdjWz7YEuwDcK9c0V4FvJzHYEhgK/cfdPo64HwN3r3f1gYC/gsPxf4yJjZicCS919SpR1bMJR7t4OOB64OD+2i1oLoB1wr7sfAiwHro62pH/Kj3R+BPw96loAzGxn4GTCH3xfB3Yws7OjrQrcfTbQCxhNGJ9MB+oL9f0V4FshP2MeCgxy9yejrmd9+b9yjwOOi7iU9sCP8rPmx4FOZjYw2pL+Kd+94e5LgacI88qoLQAWrPO3pyGEQC8VxwNT3f2DqAvJOwZ4x93r3H018CRwZMQ1AeDu/d39UHfvAHwEzC3U91aAb6H8srA/MNvd+0Rdz1pm1trMWubf/grQGZgTZU3u3t3d93L3NoS/dj/v7pF3RwBmtkN+CU1+RHEs4a+9kXL3JcD/mtm++Q/VApEuyNfzU0pkfJL3PnCEmW2f/3+zlrCXipyZ7Zb/9ZuE+fffCvW9S/5WejN7DEgBrcxsAXCDu/ePtiogdJU/A2bk580A17j7iAhrAtgDGJB/hcA2wBPuXlIv2ysxuwNPhf/naQH8zd1HRlvSP1wCDMqPK+YD50ZcD/CPP+g6AxdEXcta7j7JzIYAU4E1wDRK51j9UDPbFVgNXFzIZXTJv4xQREQ2TCMUEZGYUoCLiMSUAlxEJKYU4CIiMaUAFxGJKQW4iEhMKcBFRGLq/wHKrz+i5x7qZgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(x, model.predict(x), 'b', x,y, 'k.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 그래프에서 각 점은 우리가 실제 주었던 실제값에 해당되며, 직선은 실제값으로부터 오차를 최소화하는 W와 b의 값을 가지는 직선입니다. 이제 이 직선을 통해 9시간 30분을 공부하였을 때의 시험 성적을 예측하게 해봅시다. model.predict()은 학습이 완료된 모델이 입력된 데이터에 대해서 어떤 값을 예측하는지를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.55646]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([9.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9시간 30분을 공부하면 약 98.5점을 얻는다고 예측하고 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
