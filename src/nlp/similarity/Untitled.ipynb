{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "\n",
    "# Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
    "from konlpy.tag import Okt\n",
    "okt = Okt()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "# tokenizer : 문장에서 색인어 추출을 위해 명사,동사,알파벳,숫자 정도의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "def tokenizer(raw, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stopword=[]):\n",
    "    return [\n",
    "        word for word, tag in okt.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]\n",
    "\n",
    "# 테스트 문장\n",
    "rawdata = [\n",
    "    '남북 고위급회담 대표단 확정..남북 해빙모드 급물살',\n",
    "    '[남북 고위급 회담]장차관만 6명..판 커지는 올림픽 회담',\n",
    "    \n",
    "    '문재인 대통령과 대통령의 영부인 김정숙여사 내외의 동반 1987 관람 후 인터뷰',\n",
    "    '1987 본 문 대통령..\"그런다고 바뀌나? 함께 하면 바뀐다\"',\n",
    "    \n",
    "    '이명박 전 대통령과 전 대통령의 부인 김윤옥 여사, 그리고 전 대통령의 아들 이시형씨의 동반 검찰출석이 기대됨'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_transform, (sentence 5, feature 7)\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n",
      "[[0 1 2 0 0 0 1]\n",
      " [0 1 1 0 0 0 2]\n",
      " [1 0 0 2 1 1 0]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 0 0 3 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "vectorize = CountVectorizer(\n",
    "    tokenizer=tokenizer, \n",
    "    min_df=2    # 예제로 보기 좋게 1번 정도만 노출되는 단어들은 무시하기로 했다\n",
    "                # min_df = 0.01 : 문서의 1% 미만으로 나타나는 단어 무시\n",
    "                # min_df = 10 : 문서에 10개 미만으로 나타나는 단어 무시\n",
    "                # max_df = 0.80 : 문서의 80% 이상에 나타나는 단어 무시\n",
    "                # max_df = 10 : 10개 이상의 문서에 나타나는 단어 무시\n",
    ")\n",
    "\n",
    "# 문장에서 노출되는 feature(특징이 될만한 단어) 수를 합한 Document Term Matrix(이하 DTM) 을 리턴한다\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "\n",
    "print(\n",
    "    'fit_transform, (sentence {}, feature {})'.format(X.shape[0], X.shape[1])\n",
    ")\n",
    "# fit_transform, (sentence 5, feature 7)\n",
    "\n",
    "print(type(X))\n",
    "# <class 'scipy.sparse.csr.csr_matrix'>\n",
    "\n",
    "print(X.toarray())\n",
    "\n",
    "# [[0, 1, 2, 0, 0, 0, 1],\n",
    "# [0, 1, 1, 0, 0, 0, 2],\n",
    "# [1, 0, 0, 2, 1, 1, 0],\n",
    "# [1, 0, 0, 1, 0, 0, 0],\n",
    "# [0, 0, 0, 3, 1, 1, 0]]\n",
    "\n",
    "# 문장에서 뽑아낸 feature 들의 배열\n",
    "features = vectorize.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
