{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ref : https://blog.breezymind.com/2018/03/02/sklearn-feature_extraction-text-2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from konlpy.tag import Okt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "np.random.seed(0)\n",
    "okt = Okt()   # Twitter\" has changed to \"Okt\" since KoNLPy v0.4.5.\n",
    "\n",
    "# tokenizer : 문장에서 색인어 추출을 위해 명사,동사,알파벳,숫자 정도의 단어만 뽑아서 normalization, stemming 처리하도록 함\n",
    "def tokenizer(raw, pos=[\"Noun\",\"Alpha\",\"Verb\",\"Number\"], stopword=[]):\n",
    "    return [\n",
    "        word for word, tag in okt.pos(\n",
    "            raw, \n",
    "            norm=True,   # normalize 그랰ㅋㅋ -> 그래ㅋㅋ\n",
    "            stem=True    # stemming 바뀌나->바뀌다\n",
    "            )\n",
    "            if len(word) > 1 and tag in pos and word not in stopword\n",
    "        ]\n",
    "\n",
    "# 테스트 문장\n",
    "rawdata = [\n",
    "    '남북 고위급회담 대표단 확정..남북 해빙모드 급물살',\n",
    "    '[남북 고위급 회담]장차관만 6명..판 커지는 올림픽 회담',\n",
    "    \n",
    "    '문재인 대통령과 대통령의 영부인 김정숙여사 내외의 동반 1987 관람 후 인터뷰',\n",
    "    '1987 본 문 대통령..\"그런다고 바뀌나? 함께 하면 바뀐다\"',\n",
    "    \n",
    "    '이명박 전 대통령과 전 대통령의 부인 김윤옥 여사, 그리고 전 대통령의 아들 이시형씨의 동반 검찰출석이 기대됨'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CountVectorizer \n",
    "문서목록에서 각 문서의 feature(문장의 특징) 노출수를 가중치로 설정한 BOW 벡터를 만든다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= vocabulary_\n",
      " {'남북': 2, '고위': 1, '회담': 6, '대통령': 3, '여사': 5, '동반': 4, '1987': 0}\n",
      "\n",
      "======= fit_transform\n",
      " fit_transform, (sentence 5, feature 7)\n",
      "\n",
      "======= type(X)\n",
      " <class 'scipy.sparse.csr.csr_matrix'>\n",
      "\n",
      "======= (DTM) toarray\n",
      " [[0 1 2 0 0 0 1]\n",
      " [0 1 1 0 0 0 2]\n",
      " [1 0 0 2 1 1 0]\n",
      " [1 0 0 1 0 0 0]\n",
      " [0 0 0 3 1 1 0]]\n",
      "\n",
      "======= features\n",
      " ['1987', '고위', '남북', '대통령', '동반', '여사', '회담']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1987</th>\n",
       "      <th>고위</th>\n",
       "      <th>남북</th>\n",
       "      <th>대통령</th>\n",
       "      <th>동반</th>\n",
       "      <th>여사</th>\n",
       "      <th>회담</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1987  고위  남북  대통령  동반  여사  회담\n",
       "0     0   1   2    0   0   0   1\n",
       "1     0   1   1    0   0   0   2\n",
       "2     1   0   0    2   1   1   0\n",
       "3     1   0   0    1   0   0   0\n",
       "4     0   0   0    3   1   1   0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize = CountVectorizer(\n",
    "    tokenizer=tokenizer, \n",
    "    min_df=2    # 예제로 보기 좋게 1번 정도만 노출되는 단어들은 무시하기로 했다\n",
    "                # min_df = 0.01 : 문서의 1% 미만으로 나타나는 단어 무시\n",
    "                # min_df = 10 : 문서에 10개 미만으로 나타나는 단어 무시\n",
    "                # max_df = 0.80 : 문서의 80% 이상에 나타나는 단어 무시\n",
    "                # max_df = 10 : 10개 이상의 문서에 나타나는 단어 무시\n",
    ")\n",
    "\n",
    "# 문장에서 노출되는 feature(특징이 될만한 단어) 수를 합한 Document Term Matrix(이하 DTM) 을 리턴한다\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "print('\\n======= vocabulary_\\n',vectorize.vocabulary_)\n",
    "\n",
    "print('\\n======= fit_transform\\n','fit_transform, (sentence {}, feature {})'.format(X.shape[0], X.shape[1]))\n",
    "\n",
    "print('\\n======= type(X)\\n',type(X))\n",
    "\n",
    "print('\\n======= (DTM) toarray\\n',X.toarray())\n",
    "\n",
    "# 문장에서 뽑아낸 feature 들의 배열\n",
    "features = vectorize.get_feature_names()\n",
    "print('\\n======= features\\n',features)\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=features)\n",
    "df\n",
    "#print('\\n======= Convert to Dataframe format\\n',df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 처럼 CountVectorizer 로 DTM 을 만들면, 아래 그림과 같이 각 문장에서 feature 가 되는 단어들이 몇 번이나 노출 되는지 알 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 CountVectorizer DTM에서 내가 원하는 유사한 문장을 찾아보자.\n",
    "\n",
    "단순히 내가 원하는 문장을 search 라고 하고, search 문장이 위에서 만든 dtm 이 가지고 있는 feature 를 기준으로 어떻게 구성이 되는지 알아보고 그 feature 들이 노출되는 수의 합을 구하면 유사한 문장들을 구할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======= search\n",
      " ['1987', '대통령'] <class 'list'>\n",
      "\n",
      "======= Matched DTM\n",
      " [[0 0]\n",
      " [0 0]\n",
      " [1 2]\n",
      " [1 1]\n",
      " [0 3]] <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1987</th>\n",
       "      <th>대통령</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1987  대통령\n",
       "0     0    0\n",
       "1     0    0\n",
       "2     1    2\n",
       "3     1    1\n",
       "4     0    3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 검색 문장에서 feature를 뽑아냄\n",
    "srch=[t for t in tokenizer('1987 관람한 대통령 인터뷰 기사') if t in features]\n",
    "print('\\n======= search\\n',srch, type(srch))\n",
    "\n",
    "# dtm 에서 검색하고자 하는 feature만 뽑아낸다.\n",
    "srch_dtm = np.asarray(X.toarray())[:, [\n",
    "    # vectorize.vocabulary_.get 는 특정 feature 가 dtm 에서 가지고 있는 index값을 리턴한다\n",
    "    vectorize.vocabulary_.get(i) for i in srch\n",
    "]]\n",
    "print('\\n======= Matched DTM\\n',srch_dtm, type(srch_dtm))\n",
    "\n",
    "\n",
    "df = pd.DataFrame(srch_dtm, columns=srch)\n",
    "df\n",
    "#print('\\n======= Convert to Dataframe format\\n',df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이제 각 feature의 합을 구해서 어느 문장(row)이 가장 점수가 높은지 그리고 높은 순서대로 rawdata 에서 문장을 뽑아보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 3 2 3]\n",
      "이명박 전 대통령과 전 대통령의 부인 김윤옥 여사, 그리고 전 대통령의 아들 이시형씨의 동반 검찰출석이 기대됨 / score : 3\n",
      "문재인 대통령과 대통령의 영부인 김정숙여사 내외의 동반 1987 관람 후 인터뷰 / score : 3\n",
      "1987 본 문 대통령..\"그런다고 바뀌나? 함께 하면 바뀐다\" / score : 2\n"
     ]
    }
   ],
   "source": [
    "score = srch_dtm.sum(axis=1)\n",
    "print(score)   # array([0, 0, 3, 2, 3], dtype=int64) 문장별 feature 합계 점수\n",
    "\n",
    "for i in score.argsort()[::-1]:\n",
    "    if score[i] > 0:\n",
    "        print('{} / score : {}'.format(rawdata[i], score[i]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 문장이 가지고 있는 feature 의 빈도수 기준으로 뽑다보니 원하는 주제와는 다른 문장이 상위에 노출되었다. 이런 CountVectorizer의 특징은 모든 feature 가 동일한 점수를 가지고 있는 관계로 주제에서 중요하지 않은 feature가 빈번히 반복되는 단어가 노출 되는 경우에는 원하는 결과를 어렵게 만들기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TfidfVectorizer\n",
    "문서목록에서 각 문서의 feature를 tf-idf 값을 가중치로 설정한 BOW 벡터를 만든다. (TF-IDF에 대한 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit_transform, (sentence 5, feature 7)\n",
      "[[0.         0.45329466 0.76749457 0.         0.         0.\n",
      "  0.45329466]\n",
      " [0.         0.45329466 0.45329466 0.         0.         0.\n",
      "  0.76749457]\n",
      " [0.44832087 0.         0.         0.63009934 0.44832087 0.44832087\n",
      "  0.        ]\n",
      " [0.76944707 0.         0.         0.63871058 0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.77637396 0.44566999 0.44566999\n",
      "  0.        ]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1987</th>\n",
       "      <th>고위</th>\n",
       "      <th>남북</th>\n",
       "      <th>대통령</th>\n",
       "      <th>동반</th>\n",
       "      <th>여사</th>\n",
       "      <th>회담</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.767495</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.453295</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.767495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630099</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.448321</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.776374</td>\n",
       "      <td>0.445670</td>\n",
       "      <td>0.445670</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1987        고위        남북       대통령        동반        여사        회담\n",
       "0  0.000000  0.453295  0.767495  0.000000  0.000000  0.000000  0.453295\n",
       "1  0.000000  0.453295  0.453295  0.000000  0.000000  0.000000  0.767495\n",
       "2  0.448321  0.000000  0.000000  0.630099  0.448321  0.448321  0.000000\n",
       "3  0.769447  0.000000  0.000000  0.638711  0.000000  0.000000  0.000000\n",
       "4  0.000000  0.000000  0.000000  0.776374  0.445670  0.445670  0.000000"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize = TfidfVectorizer(\n",
    "    tokenizer=tokenizer,\n",
    "    min_df=2,\n",
    "    \n",
    "    sublinear_tf=True    # tf값에 1+log(tf)를 적용하여 tf값이 무한정 커지는 것을 막음\n",
    ")\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "\n",
    "print(\n",
    "    'fit_transform, (sentence {}, feature {})'.format(X.shape[0], X.shape[1])\n",
    ")\n",
    "\n",
    "print(X.toarray())\n",
    "\n",
    "# 문장에서 뽑아낸 feature 들의 배열\n",
    "features = vectorize.get_feature_names()\n",
    "df = pd.DataFrame(X.toarray(),columns=features)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 CountVector에서 유사문장을 뽑아낸 방법을 동일하게 TfidfVector에 적용해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1987', '대통령']\n",
      "[0.         0.         1.07842022 1.40815765 0.77637396]\n",
      "1987 본 문 대통령..\"그런다고 바뀌나? 함께 하면 바뀐다\" / score : 1.408157650537996\n",
      "문재인 대통령과 대통령의 영부인 김정숙여사 내외의 동반 1987 관람 후 인터뷰 / score : 1.0784202177170614\n",
      "이명박 전 대통령과 전 대통령의 부인 김윤옥 여사, 그리고 전 대통령의 아들 이시형씨의 동반 검찰출석이 기대됨 / score : 0.7763739568837855\n"
     ]
    }
   ],
   "source": [
    "# 검색 문장에서 feature를 뽑아냄\n",
    "srch=[t for t in tokenizer('1987 관람한 대통령 인터뷰 기사') if t in features]\n",
    "print(srch)\n",
    "\n",
    "# dtm 에서 검색하고자 하는 feature만 뽑아낸다.\n",
    "srch_dtm = np.asarray(X.toarray())[:, [\n",
    "    # vectorize.vocabulary_.get 는 특정 feature 가 dtm 에서 가지고 있는 index값을 리턴한다\n",
    "    vectorize.vocabulary_.get(i) for i in srch\n",
    "]]\n",
    "\n",
    "\n",
    "score = srch_dtm.sum(axis=1)\n",
    "print(score)   # 문장별 feature 합계 점수\n",
    "\n",
    "for i in score.argsort()[::-1]:\n",
    "    if score[i] > 0:\n",
    "        print('{} / score : {}'.format(rawdata[i], score[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "결과를 보면 하나의 feature가 가지는 score가 문장별로 다르게 적용 되어 있어, 유사 문장을 추출했을때 비교적 주제에 가까운 문장들이 상위에 노출 된 것을 볼 수 있다.\n",
    "\n",
    "# HashingVectorizer (API Reference)\n",
    ": CountVectorizer, TfidfVectorizer 와 달리 벡터화 할때 모든 feature 에 대해 사전을 만들지 않고, 해싱함수를 통해 벡터안의 인덱스를 특정하도록 한다. 큰 사전을 만들 필요가 없어 메모리 소모가 적어 대용량 텍스트를 벡터화 할때 많이 쓰인다. (Hashing Trick에 대한 참고)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 7)\n",
      "[[ 0.33333333  0.33333333 -0.33333333  0.33333333  0.33333333  0.66666667\n",
      "   0.        ]\n",
      " [ 0.          0.         -0.57735027  0.57735027  0.57735027  0.\n",
      "   0.        ]\n",
      " [ 0.          0.          0.          0.         -0.21821789 -0.43643578\n",
      "   0.87287156]\n",
      " [ 0.          0.          0.          0.81649658  0.         -0.40824829\n",
      "   0.40824829]\n",
      " [ 0.28867513  0.28867513 -0.28867513  0.28867513 -0.57735027  0.\n",
      "   0.57735027]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1987</th>\n",
       "      <th>고위</th>\n",
       "      <th>남북</th>\n",
       "      <th>대통령</th>\n",
       "      <th>동반</th>\n",
       "      <th>여사</th>\n",
       "      <th>회담</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>-0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.218218</td>\n",
       "      <td>-0.436436</td>\n",
       "      <td>0.872872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.816497</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>-0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>-0.577350</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.577350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       1987        고위        남북       대통령        동반        여사        회담\n",
       "0  0.333333  0.333333 -0.333333  0.333333  0.333333  0.666667  0.000000\n",
       "1  0.000000  0.000000 -0.577350  0.577350  0.577350  0.000000  0.000000\n",
       "2  0.000000  0.000000  0.000000  0.000000 -0.218218 -0.436436  0.872872\n",
       "3  0.000000  0.000000  0.000000  0.816497  0.000000 -0.408248  0.408248\n",
       "4  0.288675  0.288675 -0.288675  0.288675 -0.577350  0.000000  0.577350"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorize = HashingVectorizer(\n",
    "    tokenizer=tokenizer,\n",
    "    n_features=7               # 기본 feature 수를 설정하며 기본값이 2의 20승이다. 아래 예시를 위해 feature 를 7로 한정했으나, 아래 유사문장을 찾을때는 다시 n_features 주석처리 했다.\n",
    ")\n",
    "X = vectorize.fit_transform(rawdata)\n",
    "\n",
    "print(X.shape)\n",
    "# (5, 7)\n",
    "\n",
    "print(X.toarray())\n",
    "\n",
    "df = pd.DataFrame(X.toarray(),columns=features)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 처럼 HashingVectorizer에서 리턴받은 벡터화된 모든 문서(rawdata)의 형태로는 어떤 feature 가 들어가 있는지 조차 알기 어렵다. 또한 HashingVectorizer 는 사전을 저장하지 않으므로 지금까지 해온 dtm 으로 특정 feature 의 column 의 score 를 구하는 방식은 사용하기 어려울 듯하다.\n",
    "\n",
    "이제 좀 더 간단한 방법으로 유사 문장을 찾아보자. 다음은 문장 유사도 측정을 위해 이미 만들어진 벡터 X와 search 문장 벡터를 내적해서 (코사인 유사도) 를 구하고 유사문장을 찾는 과정을 보여준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 7)\n"
     ]
    }
   ],
   "source": [
    "# search 문장 벡터\n",
    "srch_vector = vectorize.transform([\n",
    "    '1987 관람한 대통령 인터뷰 기사'\n",
    "])\n",
    "\n",
    "print(srch_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         0.         0.7474103  1.         0.49587826]\n",
      "(5,)\n",
      "[3 2 4 1 0]\n",
      "1987 본 문 대통령..\"그런다고 바뀌나? 함께 하면 바뀐다\" / score : 0.9999999999999998\n",
      "문재인 대통령과 대통령의 영부인 김정숙여사 내외의 동반 1987 관람 후 인터뷰 / score : 0.7474102998962311\n",
      "이명박 전 대통령과 전 대통령의 부인 김윤옥 여사, 그리고 전 대통령의 아들 이시형씨의 동반 검찰출석이 기대됨 / score : 0.49587825840804506\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# linear_kernel는 두 벡터의 dot product 이다.\n",
    "cosine_similar = linear_kernel(srch_vector, X).flatten()\n",
    "# cosine_similar = (srch_vector*X.T).toarray().flatten()\n",
    "\n",
    "print(cosine_similar)\n",
    "\n",
    "\n",
    "print(cosine_similar.shape)\n",
    "\n",
    "# 유사한 rawdata index\n",
    "sim_rank_idx = cosine_similar.argsort()[::-1]\n",
    "print(sim_rank_idx)\n",
    "\n",
    "\n",
    "for i in sim_rank_idx:\n",
    "    if cosine_similar[i] > 0:\n",
    "        print('{} / score : {}'.format(rawdata[i], cosine_similar[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
